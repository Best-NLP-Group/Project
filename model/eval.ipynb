{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f03dc6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:26:52.215793Z",
     "iopub.status.busy": "2025-04-15T13:26:52.215573Z",
     "iopub.status.idle": "2025-04-15T13:26:52.221698Z",
     "shell.execute_reply": "2025-04-15T13:26:52.221020Z",
     "shell.execute_reply.started": "2025-04-15T13:26:52.215775Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data, DataLoader as GeoDataLoader, Batch\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77186221",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:26:52.242066Z",
     "iopub.status.busy": "2025-04-15T13:26:52.241419Z",
     "iopub.status.idle": "2025-04-15T13:26:52.252074Z",
     "shell.execute_reply": "2025-04-15T13:26:52.251354Z",
     "shell.execute_reply.started": "2025-04-15T13:26:52.242039Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d781c29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:26:52.254176Z",
     "iopub.status.busy": "2025-04-15T13:26:52.253988Z",
     "iopub.status.idle": "2025-04-15T13:26:52.316829Z",
     "shell.execute_reply": "2025-04-15T13:26:52.316338Z",
     "shell.execute_reply.started": "2025-04-15T13:26:52.254162Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "FOLDER = \"../data\"\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    with jsonlines.open(file_path) as reader:\n",
    "        data = [obj for obj in reader]\n",
    "        return data\n",
    "    \n",
    "train_data = load_jsonl(f\"{FOLDER}/train.jsonl\")\n",
    "val_data = load_jsonl(f\"{FOLDER}/validation.jsonl\")\n",
    "test_data = load_jsonl(f\"{FOLDER}/test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b44e27ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:26:52.317646Z",
     "iopub.status.busy": "2025-04-15T13:26:52.317461Z",
     "iopub.status.idle": "2025-04-15T13:26:52.322805Z",
     "shell.execute_reply": "2025-04-15T13:26:52.322113Z",
     "shell.execute_reply.started": "2025-04-15T13:26:52.317632Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DiplomacyVocabulary(Dataset):\n",
    "    def __init__(self):\n",
    "        # Initialize the vocabulary with special tokens\n",
    "        self.word2idx = {\"PAD\": 0, \"UNK\": 1}\n",
    "        self.idx2word = {0: \"PAD\", 1: \"UNK\"}\n",
    "        \n",
    "    def add_token(self, token):\n",
    "        # Add a new token to the vocabulary\n",
    "        token = token.lower()\n",
    "        if token not in self.word2idx:\n",
    "            idx = len(self.word2idx)\n",
    "            self.word2idx[token] = idx\n",
    "            self.idx2word[idx] = token\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n",
    "    \n",
    "    def tokenize(self, message):\n",
    "        message = message.lower()\n",
    "        tokens = word_tokenize(message)\n",
    "        return [self.word2idx.get(token, 1) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "956630ec-77d9-4b55-aee6-51a12dd5b6b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:26:52.323809Z",
     "iopub.status.busy": "2025-04-15T13:26:52.323549Z",
     "iopub.status.idle": "2025-04-15T13:26:52.343537Z",
     "shell.execute_reply": "2025-04-15T13:26:52.342938Z",
     "shell.execute_reply.started": "2025-04-15T13:26:52.323789Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DiplomacyDataset(Dataset):\n",
    "    def __init__(self, data, map_folder, move_folder, vocab=None, construct=False):\n",
    "        self.data = data\n",
    "        self.map_folder = map_folder\n",
    "        self.move_folder = move_folder\n",
    "        self.countries = [\"Austria\", \"England\", \"France\", \"Germany\", \"Italy\", \"Russia\", \"Turkey\", \"None\"]\n",
    "        self.province_types = [\"Inland\", \"Coastal\", \"Water\"]\n",
    "        self.unit_types = [\"A\", \"F\", \"None\"]\n",
    "        self.provinces = None\n",
    "        self.vocab = vocab if vocab else DiplomacyVocabulary()\n",
    "        \n",
    "        # Remove empty conversations\n",
    "        to_rem = []\n",
    "        for i in range(0, len(data)):\n",
    "            flag = False\n",
    "            for j in range(0, len(data[i]['messages'])):\n",
    "                message = self.preprocess_text(data[i]['messages'][j])\n",
    "                if message and data[i]['sender_labels'][j] != \"NOANNOTATION\":\n",
    "                    flag = True\n",
    "                    break\n",
    "            if not flag:\n",
    "                to_rem.append(i)\n",
    "        for i in to_rem[::-1]:\n",
    "            del data[i]\n",
    "        self.data = data\n",
    "        \n",
    "        # Construct vocabulary if needed\n",
    "        if construct:\n",
    "            for item in data:\n",
    "                for i, message in enumerate(item['messages']):\n",
    "                    message = self.preprocess_text(message)\n",
    "                    speaker = item['speakers'][i]\n",
    "                    receiver = item['receivers'][i]\n",
    "                    game_id = item['game_id']\n",
    "                    year = item['years'][i]\n",
    "                    season = item['seasons'][i].lower()\n",
    "                    sender_moves, receiver_moves = self.load_moves(f\"DiplomacyGame{game_id}_{year}_{season}\", speaker, receiver)\n",
    "                    sender = item['speakers'][i]\n",
    "                    receiver = item['receivers'][i]\n",
    "                    message = f\"{sender} to {receiver}: {message}\"\n",
    "                    for token in word_tokenize(message):\n",
    "                        self.vocab.add_token(token)\n",
    "                    for token in word_tokenize(sender_moves):\n",
    "                        self.vocab.add_token(token)\n",
    "                    for token in word_tokenize(receiver_moves):\n",
    "                        self.vocab.add_token(token)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def preprocess_text(self, sentence):\n",
    "        # Removing links\n",
    "        sentence = re.sub(r'http\\S+|www\\S+|https\\S+', '', sentence, flags=re.MULTILINE)\n",
    "        # https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
    "        emoji_pattern = re.compile(\n",
    "                    pattern = u\"[\\U0001F600-\\U0001F64F\"     # emoticons\n",
    "                                \"\\U0001F300-\\U0001F5FF\"     # symbols & pictographs\n",
    "                                \"\\U0001F680-\\U0001F6FF\"     # transport & map symbols\n",
    "                                \"\\U0001F1E0-\\U0001FAD6]+\",  # flags (iOS)\n",
    "                    flags = re.UNICODE)\n",
    "        sentence = emoji_pattern.sub(r'', sentence)\n",
    "        sentence = re.sub(r'\\s+', ' ', sentence).strip()\n",
    "        return sentence.lower()\n",
    "    \n",
    "    \n",
    "    def one_hot_encode(self, value, categories):\n",
    "        one_hot = np.zeros(len(categories))\n",
    "        one_hot[categories.index(value)] = 1\n",
    "        return one_hot\n",
    "    \n",
    "    def load_map(self, map_file):\n",
    "        with open(f\"{os.path.join(self.map_folder, map_file)}.json\", 'r') as f:\n",
    "            map_data = json.load(f)\n",
    "        if self.provinces is None:\n",
    "            self.provinces = list(map_data.keys())\n",
    "        features = [None] * len(self.provinces)\n",
    "        edges = []\n",
    "        for province, info in map_data.items():\n",
    "            country = self.one_hot_encode(info[\"controlledBy\"], self.countries)\n",
    "            province_type = self.one_hot_encode(info[\"provinceType\"], self.province_types)\n",
    "            unit_type = self.one_hot_encode(info[\"unitType\"], self.unit_types)\n",
    "            supply_centre = [0, 1] if info[\"supplyCentre\"] else [1, 0]\n",
    "            controlledBy = self.one_hot_encode(info[\"controlledBy\"], self.countries)\n",
    "            currentControl = self.one_hot_encode(info[\"currentControl\"], self.countries)\n",
    "            feature_vector = np.concatenate([country, province_type, unit_type, supply_centre, controlledBy, currentControl])\n",
    "            features[self.provinces.index(province)] = feature_vector\n",
    "            for adj in info[\"adjacency\"]:\n",
    "                edges.append((self.provinces.index(province), self.provinces.index(adj)))\n",
    "        features = torch.tensor(features, dtype=torch.float)\n",
    "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "        return features, edge_index\n",
    "    \n",
    "    def load_moves(self, move_file, sender, receiver):\n",
    "        with open(f\"{os.path.join(self.move_folder, move_file)}.json\", 'r') as f:\n",
    "            move_data = json.load(f)\n",
    "        sender_moves = \" <sep> \".join(move_data[sender.capitalize()])\n",
    "        receiver_moves = \" <sep> \".join(move_data[receiver.capitalize()])\n",
    "        return sender_moves.lower(), receiver_moves.lower()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        data = {\n",
    "            \"messages\": [],\n",
    "            \"map_features\": [],\n",
    "            \"map_edges\": [],\n",
    "            \"sender_moves\": [],\n",
    "            \"receiver_moves\": [],\n",
    "            \"labels\": []\n",
    "        }\n",
    "        for i, message in enumerate(item['messages']):\n",
    "            message = self.preprocess_text(message)\n",
    "            if not message or item['sender_labels'][i] == \"NOANNOTATION\":\n",
    "                continue\n",
    "            sender_label = 1 if item['sender_labels'][i] else 0\n",
    "            speaker = item['speakers'][i]\n",
    "            receiver = item['receivers'][i]\n",
    "            game_id = item['game_id']\n",
    "            year = item['years'][i]\n",
    "            season = item['seasons'][i].lower()\n",
    "            features, edge_index = self.load_map(f\"DiplomacyGame{game_id}_{year}_{season}\")\n",
    "            sender_moves, receiver_moves = self.load_moves(f\"DiplomacyGame{game_id}_{year}_{season}\", speaker, receiver)\n",
    "            sender = item['speakers'][i]\n",
    "            receiver = item['receivers'][i]\n",
    "            message = f\"{sender} to {receiver}: {message}\"\n",
    "            data[\"messages\"].append(self.vocab.tokenize(message))\n",
    "            data[\"map_features\"].append(features)\n",
    "            data[\"map_edges\"].append(edge_index)\n",
    "            data[\"sender_moves\"].append(self.vocab.tokenize(sender_moves))\n",
    "            data[\"receiver_moves\"].append(self.vocab.tokenize(receiver_moves))\n",
    "            data[\"labels\"].append(sender_label)\n",
    "        data[\"lengths\"] = torch.tensor(len(data[\"messages\"]), dtype=torch.long)\n",
    "        return {\n",
    "            \"messages\": data[\"messages\"],\n",
    "            \"map_features\": data[\"map_features\"],\n",
    "            \"map_edges\": data[\"map_edges\"],\n",
    "            \"sender_moves\": data[\"sender_moves\"],\n",
    "            \"receiver_moves\": data[\"receiver_moves\"],\n",
    "            \"labels\": data[\"labels\"],\n",
    "            \"lengths\": data[\"lengths\"],\n",
    "        }\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d51480a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:26:52.344432Z",
     "iopub.status.busy": "2025-04-15T13:26:52.344198Z",
     "iopub.status.idle": "2025-04-15T13:27:10.207934Z",
     "shell.execute_reply": "2025-04-15T13:27:10.207403Z",
     "shell.execute_reply.started": "2025-04-15T13:26:52.344416Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MOVE_FOLDER = \"../moves_sentences\"\n",
    "MAP_FOLDER = \"../moves_map\"\n",
    "\n",
    "train_dataset = DiplomacyDataset(train_data, MAP_FOLDER, MOVE_FOLDER, construct=True)\n",
    "vocab = train_dataset.vocab\n",
    "val_dataset = DiplomacyDataset(val_data, MAP_FOLDER, MOVE_FOLDER, vocab=vocab)\n",
    "test_dataset = DiplomacyDataset(test_data, MAP_FOLDER, MOVE_FOLDER, vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "233c5f77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:27:10.208811Z",
     "iopub.status.busy": "2025-04-15T13:27:10.208629Z",
     "iopub.status.idle": "2025-04-15T13:27:10.215115Z",
     "shell.execute_reply": "2025-04-15T13:27:10.214355Z",
     "shell.execute_reply.started": "2025-04-15T13:27:10.208796Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch_messages = []\n",
    "    batch_map_features = []\n",
    "    batch_map_edges = []\n",
    "    batch_sender_moves = []\n",
    "    batch_receiver_moves = []\n",
    "    batch_labels = []\n",
    "    batch_length = []\n",
    "    \n",
    "    for item in batch:\n",
    "        batch_messages += item[\"messages\"]\n",
    "        batch_map_features += item[\"map_features\"]\n",
    "        batch_map_edges += item[\"map_edges\"]\n",
    "        batch_sender_moves += item[\"sender_moves\"]\n",
    "        batch_receiver_moves += item[\"receiver_moves\"]\n",
    "        batch_labels += item[\"labels\"]\n",
    "        batch_length += [item[\"lengths\"]]\n",
    "        \n",
    "    batch_messages = pad_sequence([torch.tensor(m) for m in batch_messages], batch_first=True, padding_value=0)\n",
    "    batch_sender_moves = pad_sequence([torch.tensor(m) for m in batch_sender_moves], batch_first=True, padding_value=0)\n",
    "    batch_receiver_moves = pad_sequence([torch.tensor(m) for m in batch_receiver_moves], batch_first=True, padding_value=0)\n",
    "    batch_map_features = torch.stack(batch_map_features)\n",
    "    batch_map_edges = torch.stack(batch_map_edges)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": batch_messages,\n",
    "        \"map_features\": batch_map_features,\n",
    "        \"map_edges\": batch_map_edges,\n",
    "        \"sender_moves\": batch_sender_moves,\n",
    "        \"receiver_moves\": batch_receiver_moves,\n",
    "        \"labels\": torch.tensor(batch_labels, dtype=torch.long),\n",
    "        \"length\": torch.tensor(batch_length, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "802f4bbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:27:10.216055Z",
     "iopub.status.busy": "2025-04-15T13:27:10.215795Z",
     "iopub.status.idle": "2025-04-15T13:27:10.246181Z",
     "shell.execute_reply": "2025-04-15T13:27:10.245338Z",
     "shell.execute_reply.started": "2025-04-15T13:27:10.216040Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2460b62f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:27:44.219842Z",
     "iopub.status.busy": "2025-04-15T13:27:44.219089Z",
     "iopub.status.idle": "2025-04-15T13:27:44.223940Z",
     "shell.execute_reply": "2025-04-15T13:27:44.223342Z",
     "shell.execute_reply.started": "2025-04-15T13:27:44.219812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Encodes the concatenated one-hot vectors of the map\n",
    "class FeatureVectorEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(FeatureVectorEncoder, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "424005eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:27:44.226364Z",
     "iopub.status.busy": "2025-04-15T13:27:44.226146Z",
     "iopub.status.idle": "2025-04-15T13:27:44.249456Z",
     "shell.execute_reply": "2025-04-15T13:27:44.248794Z",
     "shell.execute_reply.started": "2025-04-15T13:27:44.226348Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Encodes the player moves\n",
    "class MoveEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, output_dim, pretrained_embeddings=None):\n",
    "        super(MoveEncoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, 200)\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n",
    "            self.embedding.weight.requires_grad = False\n",
    "        self.lstm = nn.LSTM(200, output_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(output_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        outputs = []\n",
    "        for i in range(x.size(0)):\n",
    "            emb = self.embedding(x[i].unsqueeze(0))\n",
    "            _, (hidden, _) = self.lstm(emb)\n",
    "            hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
    "            out = self.fc(hidden)\n",
    "            outputs.append(out.squeeze(0))\n",
    "        return torch.stack(outputs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9493094",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:27:44.250575Z",
     "iopub.status.busy": "2025-04-15T13:27:44.250322Z",
     "iopub.status.idle": "2025-04-15T13:27:44.269904Z",
     "shell.execute_reply": "2025-04-15T13:27:44.269372Z",
     "shell.execute_reply.started": "2025-04-15T13:27:44.250554Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DetectionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, pretrained_embeddings=None):\n",
    "        super(DetectionModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, 200)\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n",
    "            self.embedding.weight.requires_grad = False\n",
    "        self.feature_vector_encoder = FeatureVectorEncoder(32, 32).to(device)\n",
    "        self.move_encoder = MoveEncoder(vocab_size, 32, pretrained_embeddings=pretrained_embeddings)\n",
    "        self.gan1 = GATConv(32, 16, heads=4, dropout=0.4, concat=True)\n",
    "        self.gan2 = GATConv(16*4, 64, heads=2, dropout = 0.1, concat = False)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(64)\n",
    "        self.norm2 = nn.LayerNorm(64)\n",
    "        \n",
    "        self.message_lstm = nn.LSTM(200, 128, batch_first=True, bidirectional=True)\n",
    "        self.context_lstm = nn.LSTM(256, 128, batch_first=True, bidirectional=False)\n",
    "        \n",
    "        self.fusion = nn.Linear(448, 128)\n",
    "        self.classifier = nn.Linear(128, 2)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.norm3 = nn.LayerNorm(128)\n",
    "        \n",
    "    \n",
    "    def get_graph_embeddings(self, x, edge_index):\n",
    "        graph_embeddings = []\n",
    "        for i in range(0, x.size(0), 32):\n",
    "            curr = x[i:i + 32].to(device)\n",
    "            edge = edge_index[i:i + 32]\n",
    "            curr = self.feature_vector_encoder(curr) # Getting feature vectors\n",
    "            curr = [Data(x=curr[j], edge_index=edge[j]) for j in range(len(curr))]\n",
    "            curr = Batch.from_data_list(curr).to(device)\n",
    "            # Passing graph through GATConv layers\n",
    "            y = self.gan1(curr.x, curr.edge_index)\n",
    "            y = self.norm1(y)\n",
    "            y = self.gan2(y, curr.edge_index).to(device)\n",
    "            y = self.norm2(y)\n",
    "            graph_embeddings.extend(y)\n",
    "        graph_embeddings = torch.stack(graph_embeddings, dim=0)\n",
    "        return graph_embeddings\n",
    "    \n",
    "    def get_message_embeddings(self, x):\n",
    "        conversation_len = x.size(0)\n",
    "        message_embeddings = []\n",
    "        for i in range(0, conversation_len):\n",
    "            message = x[i].unsqueeze(0)\n",
    "            message = message[message != 0]\n",
    "            message = message.unsqueeze(0)\n",
    "            message = self.embedding(message)\n",
    "            _, (hidden, _) = self.message_lstm(message)\n",
    "            # Getting the last hidden state of the LSTM for each message\n",
    "            hidden = torch.cat((hidden[0], hidden[1]), dim=-1)\n",
    "            message_embeddings.append(hidden)\n",
    "        message_embeddings = torch.stack(message_embeddings, dim=0)\n",
    "        return message_embeddings\n",
    "    \n",
    "    def forward(self, messages, map_features, map_edges, sender_moves, receiver_moves, lengths):\n",
    "        lengths = lengths.cpu()\n",
    "        map_embeddings = self.get_graph_embeddings(map_features, map_edges) \n",
    "        \n",
    "        sender_moves = self.move_encoder(sender_moves)\n",
    "        receiver_moves = self.move_encoder(receiver_moves)\n",
    "        \n",
    "        moves = torch.cat((sender_moves, receiver_moves), dim=-1) # Concatenating sender and receiver moves (query)\n",
    "        \n",
    "        batch_size = messages.size(0)\n",
    "        map_embeddings = map_embeddings.view(batch_size, -1, 64) # Reshaping to (batch_size, num_provinces, 64) (key, value)\n",
    "        \n",
    "        query = moves.unsqueeze(1)\n",
    "        attn_scores = torch.bmm(query, map_embeddings.transpose(1, 2)).squeeze(1)\n",
    "        \n",
    "        attn_scores = attn_scores.unsqueeze(1)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        attn_output = torch.bmm(attn_weights, map_embeddings).squeeze(1)\n",
    "        \n",
    "        message_embeddings = self.get_message_embeddings(messages)\n",
    "        conversation_messages = torch.split(message_embeddings, lengths.tolist())        \n",
    "        conversation_messages = pad_sequence(conversation_messages, batch_first=True, padding_value=0)\n",
    "        conversation_messages = conversation_messages.squeeze(2)\n",
    "        conversation_messages = pack_padded_sequence(conversation_messages, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        conversation_messages, _ = self.context_lstm(conversation_messages)\n",
    "        conversation_embeddings, _ = pad_packed_sequence(conversation_messages, batch_first=True) \n",
    "        \n",
    "        causal_embeddings = []\n",
    "        for i, length in enumerate(lengths):\n",
    "            for j in range(length.item()):\n",
    "                # Only taking the representation of the messages in the conversation so far\n",
    "                causal_embeddings.append(conversation_embeddings[i][j])\n",
    "        causal_embeddings = torch.stack(causal_embeddings, dim=0)\n",
    "        \n",
    "        message_embeddings = message_embeddings.squeeze(1)\n",
    "        \n",
    "        # Fusing the message embeddings, causal embeddings, and attention output\n",
    "        fused = torch.cat((message_embeddings, causal_embeddings, attn_output), dim=-1)\n",
    "        fused = self.fusion(fused)\n",
    "        x = self.norm3(fused)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.classifier(x)\n",
    "        return logits.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb06a1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 11/11 [00:25<00:00,  2.34s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro F1: 0.5463822432375554\n",
      "Test Weighted F1: 0.8531173194606964\n",
      "Test Accuracy: 0.8513513513513513\n",
      "Confusion Matrix:\n",
      "[[  43  197]\n",
      " [ 210 2288]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = DetectionModel(len(vocab)).to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_preds = []\n",
    "    test_labels = []\n",
    "    for batch in tqdm(test_dataloader, desc=\"Test\", unit=\"batch\"):\n",
    "        messages = batch[\"messages\"].to(device)\n",
    "        map_features = batch[\"map_features\"].to(device)\n",
    "        map_edges = batch[\"map_edges\"].to(device)\n",
    "        sender_moves = batch[\"sender_moves\"].to(device)\n",
    "        receiver_moves = batch[\"receiver_moves\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        lengths = batch[\"length\"].to(device)\n",
    "    \n",
    "        logits = model(messages, map_features, map_edges, sender_moves, receiver_moves, lengths)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        \n",
    "test_f1 = f1_score(test_labels, test_preds, average='macro')\n",
    "test_weighted_f1 = f1_score(test_labels, test_preds, average='weighted')\n",
    "test_accuracy = accuracy_score(test_labels, test_preds)\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "print(f'Test Macro F1: {test_f1}')\n",
    "print(f'Test Weighted F1: {test_weighted_f1}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print('Confusion Matrix:')\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7142588,
     "sourceId": 11403405,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7142648,
     "sourceId": 11403490,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7145236,
     "sourceId": 11406819,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7149329,
     "sourceId": 11415151,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
